{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "# Hyperplane: separates two classes\n",
    "# support vectors: extreame data points\n",
    "# margins 2/||w||<>\n",
    "'''\n",
    "hard margin(exact point)/ soft margin (tolerance)\n",
    "'''\n",
    "# plot v1 against v2, separate hyperplane between two classes with margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal tricks\\nlinearly separable projecting by higher dimensions\\nSVR is similar SVC\\nOutput is continuous number rather than a category\\nGoal is to minimize error and obtain a minimum margin interval which contains the maximum number of data points\\n\\nCommonly used Kernal Functions\\n1. Linear function\\n2. RBF (radical basis function)\\n3. \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data not separable\n",
    "'''\n",
    "kernal tricks\n",
    "linearly separable projecting by higher dimensions\n",
    "SVR is similar SVC\n",
    "Output is continuous number rather than a category\n",
    "Goal is to minimize error and obtain a minimum margin interval which contains the maximum number of data points\n",
    "\n",
    "Commonly used Kernal Functions\n",
    "1. Linear function\n",
    "2. RBF (radical basis function)\n",
    "3. Polynomial\n",
    "4. Exponential\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     sex     bmi  children smoker     region      charges\n",
      "0    19  female  27.900         0    yes  southwest  16884.92400\n",
      "1    18    male  33.770         1     no  southeast   1725.55230\n",
      "2    28    male  33.000         3     no  southeast   4449.46200\n",
      "3    33    male  22.705         0     no  northwest  21984.47061\n",
      "4    32    male  28.880         0     no  northwest   3866.85520\n",
      "5    31  female  25.740         0     no  southeast   3756.62160\n",
      "6    46  female  33.440         1     no  southeast   8240.58960\n",
      "7    37  female  27.740         3     no  northwest   7281.50560\n",
      "8    37    male  29.830         2     no  northeast   6406.41070\n",
      "9    60  female  25.840         0     no  northwest  28923.13692\n",
      "10   25    male  26.220         0     no  northeast   2721.32080\n",
      "11   62  female  26.290         0    yes  southeast  27808.72510\n",
      "12   23    male  34.400         0     no  southwest   1826.84300\n",
      "13   56  female  39.820         0     no  southeast  11090.71780\n",
      "14   27    male     NaN         0    yes  southeast  39611.75770\n",
      "bmi    5\n",
      "dtype: int64\n",
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n",
      "    age     sex        bmi  children smoker     region      charges\n",
      "0    19  female  27.900000         0    yes  southwest  16884.92400\n",
      "1    18    male  33.770000         1     no  southeast   1725.55230\n",
      "2    28    male  33.000000         3     no  southeast   4449.46200\n",
      "3    33    male  22.705000         0     no  northwest  21984.47061\n",
      "4    32    male  28.880000         0     no  northwest   3866.85520\n",
      "5    31  female  25.740000         0     no  southeast   3756.62160\n",
      "6    46  female  33.440000         1     no  southeast   8240.58960\n",
      "7    37  female  27.740000         3     no  northwest   7281.50560\n",
      "8    37    male  29.830000         2     no  northeast   6406.41070\n",
      "9    60  female  25.840000         0     no  northwest  28923.13692\n",
      "10   25    male  26.220000         0     no  northeast   2721.32080\n",
      "11   62  female  26.290000         0    yes  southeast  27808.72510\n",
      "12   23    male  34.400000         0     no  southwest   1826.84300\n",
      "13   56  female  39.820000         0     no  southeast  11090.71780\n",
      "14   27    male  30.658545         0    yes  southeast  39611.75770\n",
      "Series([], dtype: int64)\n",
      "Pandas factorize function for label encoding with series\n",
      "0    southwest\n",
      "1    southeast\n",
      "2    southeast\n",
      "3    northwest\n",
      "4    northwest\n",
      "5    southeast\n",
      "6    southeast\n",
      "7    northwest\n",
      "8    northeast\n",
      "9    northwest\n",
      "Name: region, dtype: object\n",
      "Index(['southwest', 'southeast', 'northwest', 'northeast'], dtype='object')\n",
      "[0 1 1 2 2 1 1 2 3 2]\n",
      "{'southwest': 0, 'southeast': 1, 'northwest': 1, 'northeast': 2}\n",
      "Pandas get_dummies function for one hot encoding with series\n",
      "0    southwest\n",
      "1    southeast\n",
      "2    southeast\n",
      "3    northwest\n",
      "4    northwest\n",
      "5    southeast\n",
      "6    southeast\n",
      "7    northwest\n",
      "8    northeast\n",
      "9    northwest\n",
      "Name: region, dtype: object\n",
      "   _northeast  _northwest  _southeast  _southwest\n",
      "0           0           0           0           1\n",
      "1           0           0           1           0\n",
      "2           0           0           1           0\n",
      "3           0           1           0           0\n",
      "4           0           1           0           0\n",
      "5           0           0           1           0\n",
      "6           0           0           1           0\n",
      "7           0           1           0           0\n",
      "8           1           0           0           0\n",
      "9           0           1           0           0\n",
      "Sklearn label encoder results for sex:\n",
      "{'female': 0, 'male': 1}\n",
      "  sex\n",
      "0   0\n",
      "1   1\n",
      "2   1\n",
      "3   1\n",
      "4   1\n",
      "5   0\n",
      "6   0\n",
      "7   0\n",
      "8   1\n",
      "9   0\n",
      "Sklearn label encoder results for smoker:\n",
      "{'no': 0, 'yes': 1}\n",
      "  smoker\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "Sklearn one hot encoder results for region:\n",
      "   northeast  northwest  southeast  southwest\n",
      "0        0.0        0.0        0.0        1.0\n",
      "1        0.0        0.0        1.0        0.0\n",
      "2        0.0        0.0        1.0        0.0\n",
      "3        0.0        1.0        0.0        0.0\n",
      "4        0.0        1.0        0.0        0.0\n",
      "5        0.0        0.0        1.0        0.0\n",
      "6        0.0        0.0        1.0        0.0\n",
      "7        0.0        1.0        0.0        0.0\n",
      "8        1.0        0.0        0.0        0.0\n",
      "9        0.0        1.0        0.0        0.0\n",
      "lr.coef_: [[ 3.62027494e+03  1.95077869e+03  6.85873820e+02  1.18478858e+17\n",
      "   1.20234031e+17  1.24970009e+17  1.22785507e+17 -3.64420788e+01\n",
      "   9.31222858e+03]]\n",
      "lr.intercept_: [13145.95343661]\n",
      "lr train score 0.728, lr test score: 0.786\n",
      "poly train score 0.840, poly test score: 0.852\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Apr 28 15:46:31 2019\n",
    "\n",
    "@author: berkunis\n",
    "\"\"\"\n",
    "##############################################01_02_PythonLibraries#####################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import data\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\")\n",
    "\n",
    "#see the first 15 lines of data\n",
    "print(data.head(15))\n",
    "\n",
    "############################################01_03_HandlingMissingValues###################################################\n",
    "\n",
    "#check how many values are missing (NaN) before we apply the methods below \n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "#fill in the missing values (we will look at 4 options for this course - there are so many other methods out there.)\n",
    "\n",
    "#option0 for dropping the entire column\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\") # reloading fresh dataset for option 0\n",
    "data.drop('bmi', axis = 1, inplace = True)\n",
    "#check how many values are missing (NaN) - after we dropped 'bmi'\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "#option1 for dropping NAN\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\") # reloading fresh dataset for option 1\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "#check how many values are missing (NaN) - after we filled in the NaN\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "#option2 for filling NaN # reloading fresh dataset for option 2\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\")\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(data['bmi'].values.reshape(-1, 1))\n",
    "data['bmi'] = imputer.transform(data['bmi'].values.reshape(-1, 1))\n",
    "#check how many values are missing (NaN) - after we filled in the NaN\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "#option3 for filling NaN # reloading fresh dataset for option 3\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\")\n",
    "data['bmi'].fillna(data['bmi'].mean(), inplace = True)\n",
    "print(data.head(15))\n",
    "#check how many values are missing (NaN) - after we filled in the NaN\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "\n",
    "\n",
    "############################################01_04_ConvertCategoricalDataintoNumbers##############################################\n",
    "#option0: pandas factorizing: maps each category to a different integer = label encoder \n",
    "\n",
    "#create series for pandas\n",
    "\n",
    "region = data[\"region\"] # series \n",
    "region_encoded, region_categories = pd.factorize(region)\n",
    "factor_region_mapping = dict(zip(region_categories, region_encoded)) #mapping of encoded numbers and original categories. \n",
    "\n",
    "print(\"Pandas factorize function for label encoding with series\")  \n",
    "print(region[:10]) #original version \n",
    "print(region_categories) #list of categories\n",
    "print(region_encoded[:10]) #encoded numbers for categories \n",
    "print(factor_region_mapping) # print factor mapping\n",
    "\n",
    "#option1: pandas get_dummies: maps each category to 0 (cold) or 1 (hot) = one hot encoder \n",
    "\n",
    "#create series for pandas\n",
    "region = data[\"region\"] # series \n",
    "region_encoded = pd.get_dummies(region, prefix='')\n",
    "\n",
    "print(\"Pandas get_dummies function for one hot encoding with series\")  \n",
    "\n",
    "print(region[:10]) #original version \n",
    "print(region_encoded[:10]) #encoded numbers for categories \n",
    "\n",
    "#option2: sklearn label encoding: maps each category to a different integer\n",
    "\n",
    "#create ndarray for label encodoing (sklearn)\n",
    "sex = data.iloc[:,1:2].values\n",
    "smoker = data.iloc[:,4:5].values\n",
    "\n",
    "#label encoder = le\n",
    "\n",
    "## le for sex\n",
    "le = LabelEncoder()\n",
    "sex[:,0] = le.fit_transform(sex[:,0])\n",
    "sex = pd.DataFrame(sex)\n",
    "sex.columns = ['sex']\n",
    "le_sex_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Sklearn label encoder results for sex:\")  \n",
    "print(le_sex_mapping)\n",
    "print(sex[:10])\n",
    "\n",
    "## le for smoker\n",
    "le = LabelEncoder()\n",
    "smoker[:,0] = le.fit_transform(smoker[:,0])\n",
    "smoker = pd.DataFrame(smoker)\n",
    "smoker.columns = ['smoker']\n",
    "le_smoker_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Sklearn label encoder results for smoker:\") \n",
    "print(le_smoker_mapping)\n",
    "print(smoker[:10])\n",
    "\n",
    "#option3: sklearn one hot encoding: maps each category to 0 (cold) or 1 (hot) \n",
    "\n",
    "#one hot encoder = ohe\n",
    "\n",
    "#create ndarray for one hot encodoing (sklearn)\n",
    "region = data.iloc[:,5:6].values #ndarray\n",
    "\n",
    "## ohe for region\n",
    "ohe = OneHotEncoder() \n",
    "\n",
    "region = ohe.fit_transform(region).toarray()\n",
    "region = pd.DataFrame(region)\n",
    "region.columns = ['northeast', 'northwest', 'southeast', 'southwest']\n",
    "print(\"Sklearn one hot encoder results for region:\")   \n",
    "print(region[:10])\n",
    "\n",
    "\n",
    "############################################01_05_DividingtheDataintoTestandTrain##############################################\n",
    "\n",
    "#putting the data together:\n",
    "\n",
    "##take the numerical data from the original data\n",
    "X_num = data[['age', 'bmi', 'children']].copy()\n",
    "\n",
    "##take the encoded data and add to numerical data\n",
    "X_final = pd.concat([X_num, region, sex, smoker], axis = 1)\n",
    "\n",
    "#define y as being the \"charges column\" from the original dataset\n",
    "y_final = data[['charges']].copy()\n",
    "\n",
    "#Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.33, random_state = 0 )\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data[['age']], y_final, test_size = 0.33, random_state = 0 )\n",
    "\n",
    "############################################01_06_FeatureScaling##############################################\n",
    "\n",
    "###normalized scaler (fit transform on train, fit only on test)\n",
    "#n_scaler = MinMaxScaler()\n",
    "#X_train = n_scaler.fit_transform(X_train.astype(np.float))\n",
    "#X_test= n_scaler.transform(X_test.astype(np.float))\n",
    "\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "s_scaler = StandardScaler()\n",
    "X_train = s_scaler.fit_transform(X_train.astype(np.float))\n",
    "X_test= s_scaler.transform(X_test.astype(np.float))\n",
    "\n",
    "\n",
    "############################################02_02_LinearRegression##############################################\n",
    "\n",
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print(\"lr.coef_: {}\".format(lr.coef_))\n",
    "print(\"lr.intercept_: {}\".format(lr.intercept_))\n",
    "print('lr train score %.3f, lr test score: %.3f' % (\n",
    "lr.score(X_train,y_train),\n",
    "lr.score(X_test, y_test)))\n",
    "############################################02_03_PolynomialRegression##############################################\n",
    "\n",
    "poly = PolynomialFeatures (degree = 3)\n",
    "X_poly = poly.fit_transform(X_final)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_poly,y_final, test_size = 0.33, random_state = 0)\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train.astype(np.float))\n",
    "X_test= sc.transform(X_test.astype(np.float))\n",
    "\n",
    "#fit model\n",
    "poly_lr = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = poly_lr.predict(X_train)\n",
    "y_test_pred = poly_lr.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print('poly train score %.3f, poly test score: %.3f' % (\n",
    "poly_lr.score(X_train,y_train),\n",
    "poly_lr.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svr.coef_: [[3652.88084977  202.46754224  475.97904631  179.67244105   32.53987879\n",
      "  -126.02330398  -76.96879816 -184.83769075 6571.51888242]]\n",
      "svr.intercept_: [10370.82641928]\n",
      "svr train score 0.597920, svr test score 0.618942\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(kernel='linear', C= 300)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final,y_final,test_size=0.33,random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "# fit model\n",
    "svr = svr.fit(X_train, y_train.values.ravel())\n",
    "y_train_pred =  svr.predict(X_train)\n",
    "y_train_pred = svr.predict(X_test)\n",
    "\n",
    "print(\"svr.coef_: {}\".format(svr.coef_))\n",
    "print(\"svr.intercept_: {}\".format(svr.intercept_))\n",
    "print('svr train score %3f, svr test score %3f'%(svr.score(X_train,y_train),svr.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=300, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Kernel handles the main work of an operating system:\n",
    "'''\n",
    "\t1. Allocates time & memory to programs\n",
    "\t2. Handles File System\n",
    "\t3. Responds to various Calls\n",
    "'''\n",
    "\n",
    "# kernel methods (also called Kernel functions) are sets of different types of algorithms that are being used for pattern analysis. \n",
    "\n",
    "'''\n",
    "SVM (Support Vector Machines) which are used in classification and regression problems.\n",
    "A hyperplane is one dimension less than the ambient plane.\n",
    "\n",
    "K(x, y)=<f(x), f(y)> where,\n",
    "K is the kernel function,\n",
    "X and Y are the dimensional inputs,\n",
    "f is the map from n-dimensional to m-dimensional space and,\n",
    "< x, y > is the dot product.\n",
    "\n",
    "e.g.\n",
    "f(2, 3, 4)=(4, 6, 8, 6, 9, 12, 8, 12, 16)and\n",
    "f(3 ,4, 5)=(9, 12, 15, 12, 16, 20, 15, 20, 25)\n",
    "\n",
    "f (x). f (y) = f(2,3,4) . f(3,4,5)=\n",
    "(36 + 72 + 120 + 72 +144 + 240 + 120 + 240 + 400) = 1444\n",
    "\n",
    "K(x, y) = (2*3 + 3*4 + 4*5) ^2=(6 + 12 + 20)^2=38*38=1444.\n",
    "\n",
    "1. Linear\n",
    "2. Polynomial\n",
    "3. Guassian ==> example of radial basis function\n",
    "4. Exponential ==> guassian with the square of the norm removed ==> radial basis function\n",
    "5. Laplacian ==> less prone to changes = exponential \n",
    "6. Hyperbolic or the Sigmoid (neural network) ==> activation function for the sigmoid kernel is the bipolar sigmoid function\n",
    "                                              ==> popular in SVM\n",
    "7. Anova radial basis kernel ==> perform well in multidimensional regression problems like Gaussian and Laplacian Kernel (radial basis kernel)\n",
    "'''\n",
    "\n",
    "\n",
    "# C\n",
    "\n",
    "'''\n",
    "SVM  always look for two things contradictory:\n",
    "1. larger margin\n",
    "2. lower misclassification rate \n",
    "\n",
    "for training data ==> aim for lower misclassification rate\n",
    "for testing data ==> aim for better result of higher margin for better result\n",
    "\n",
    "Large C ==> smaller margin\n",
    "Small C ==> Large margin\n",
    "\n",
    "Best option: trying bunch of different values and choose the value which gives you lowest misclassification rate on testing data.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
