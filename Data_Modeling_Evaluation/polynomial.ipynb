{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     sex     bmi  children smoker     region      charges\n",
      "0    19  female  27.900         0    yes  southwest  16884.92400\n",
      "1    18    male  33.770         1     no  southeast   1725.55230\n",
      "2    28    male  33.000         3     no  southeast   4449.46200\n",
      "3    33    male  22.705         0     no  northwest  21984.47061\n",
      "4    32    male  28.880         0     no  northwest   3866.85520\n",
      "5    31  female  25.740         0     no  southeast   3756.62160\n",
      "6    46  female  33.440         1     no  southeast   8240.58960\n",
      "7    37  female  27.740         3     no  northwest   7281.50560\n",
      "8    37    male  29.830         2     no  northeast   6406.41070\n",
      "9    60  female  25.840         0     no  northwest  28923.13692\n",
      "10   25    male  26.220         0     no  northeast   2721.32080\n",
      "11   62  female  26.290         0    yes  southeast  27808.72510\n",
      "12   23    male  34.400         0     no  southwest   1826.84300\n",
      "13   56  female  39.820         0     no  southeast  11090.71780\n",
      "14   27    male     NaN         0    yes  southeast  39611.75770\n",
      "bmi    5\n",
      "dtype: int64\n",
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n",
      "    age     sex        bmi  children smoker     region      charges\n",
      "0    19  female  27.900000         0    yes  southwest  16884.92400\n",
      "1    18    male  33.770000         1     no  southeast   1725.55230\n",
      "2    28    male  33.000000         3     no  southeast   4449.46200\n",
      "3    33    male  22.705000         0     no  northwest  21984.47061\n",
      "4    32    male  28.880000         0     no  northwest   3866.85520\n",
      "5    31  female  25.740000         0     no  southeast   3756.62160\n",
      "6    46  female  33.440000         1     no  southeast   8240.58960\n",
      "7    37  female  27.740000         3     no  northwest   7281.50560\n",
      "8    37    male  29.830000         2     no  northeast   6406.41070\n",
      "9    60  female  25.840000         0     no  northwest  28923.13692\n",
      "10   25    male  26.220000         0     no  northeast   2721.32080\n",
      "11   62  female  26.290000         0    yes  southeast  27808.72510\n",
      "12   23    male  34.400000         0     no  southwest   1826.84300\n",
      "13   56  female  39.820000         0     no  southeast  11090.71780\n",
      "14   27    male  30.658545         0    yes  southeast  39611.75770\n",
      "Series([], dtype: int64)\n",
      "Pandas factorize function for label encoding with series\n",
      "0    southwest\n",
      "1    southeast\n",
      "2    southeast\n",
      "3    northwest\n",
      "4    northwest\n",
      "5    southeast\n",
      "6    southeast\n",
      "7    northwest\n",
      "8    northeast\n",
      "9    northwest\n",
      "Name: region, dtype: object\n",
      "Index(['southwest', 'southeast', 'northwest', 'northeast'], dtype='object')\n",
      "[0 1 1 2 2 1 1 2 3 2]\n",
      "{'southwest': 0, 'southeast': 1, 'northwest': 1, 'northeast': 2}\n",
      "Pandas get_dummies function for one hot encoding with series\n",
      "0    southwest\n",
      "1    southeast\n",
      "2    southeast\n",
      "3    northwest\n",
      "4    northwest\n",
      "5    southeast\n",
      "6    southeast\n",
      "7    northwest\n",
      "8    northeast\n",
      "9    northwest\n",
      "Name: region, dtype: object\n",
      "   _northeast  _northwest  _southeast  _southwest\n",
      "0           0           0           0           1\n",
      "1           0           0           1           0\n",
      "2           0           0           1           0\n",
      "3           0           1           0           0\n",
      "4           0           1           0           0\n",
      "5           0           0           1           0\n",
      "6           0           0           1           0\n",
      "7           0           1           0           0\n",
      "8           1           0           0           0\n",
      "9           0           1           0           0\n",
      "Sklearn label encoder results for sex:\n",
      "{'female': 0, 'male': 1}\n",
      "  sex\n",
      "0   0\n",
      "1   1\n",
      "2   1\n",
      "3   1\n",
      "4   1\n",
      "5   0\n",
      "6   0\n",
      "7   0\n",
      "8   1\n",
      "9   0\n",
      "Sklearn label encoder results for smoker:\n",
      "{'no': 0, 'yes': 1}\n",
      "  smoker\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "Sklearn one hot encoder results for region:\n",
      "   northeast  northwest  southeast  southwest\n",
      "0        0.0        0.0        0.0        1.0\n",
      "1        0.0        0.0        1.0        0.0\n",
      "2        0.0        0.0        1.0        0.0\n",
      "3        0.0        1.0        0.0        0.0\n",
      "4        0.0        1.0        0.0        0.0\n",
      "5        0.0        0.0        1.0        0.0\n",
      "6        0.0        0.0        1.0        0.0\n",
      "7        0.0        1.0        0.0        0.0\n",
      "8        1.0        0.0        0.0        0.0\n",
      "9        0.0        1.0        0.0        0.0\n",
      "lr.coef_: [[ 3.62027494e+03  1.95077869e+03  6.85873820e+02  1.18478858e+17\n",
      "   1.20234031e+17  1.24970009e+17  1.22785507e+17 -3.64420788e+01\n",
      "   9.31222858e+03]]\n",
      "lr.intercept_: [13145.95343661]\n",
      "lr train score 0.728, lr test score: 0.786\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Apr 28 15:46:31 2019\n",
    "\n",
    "@author: berkunis\n",
    "\"\"\"\n",
    "##############################################01_02_PythonLibraries#####################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import data\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\")\n",
    "\n",
    "#see the first 15 lines of data\n",
    "print(data.head(15))\n",
    "\n",
    "############################################01_03_HandlingMissingValues###################################################\n",
    "\n",
    "#check how many values are missing (NaN) before we apply the methods below \n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "#fill in the missing values (we will look at 4 options for this course - there are so many other methods out there.)\n",
    "\n",
    "#option0 for dropping the entire column\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\") # reloading fresh dataset for option 0\n",
    "data.drop('bmi', axis = 1, inplace = True)\n",
    "#check how many values are missing (NaN) - after we dropped 'bmi'\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "#option1 for dropping NAN\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\") # reloading fresh dataset for option 1\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "#check how many values are missing (NaN) - after we filled in the NaN\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "#option2 for filling NaN # reloading fresh dataset for option 2\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\")\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(data['bmi'].values.reshape(-1, 1))\n",
    "data['bmi'] = imputer.transform(data['bmi'].values.reshape(-1, 1))\n",
    "#check how many values are missing (NaN) - after we filled in the NaN\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "#option3 for filling NaN # reloading fresh dataset for option 3\n",
    "data = pd.read_csv(\"Datasets/insurance.csv\")\n",
    "data['bmi'].fillna(data['bmi'].mean(), inplace = True)\n",
    "print(data.head(15))\n",
    "#check how many values are missing (NaN) - after we filled in the NaN\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n",
    "\n",
    "############################################01_04_ConvertCategoricalDataintoNumbers##############################################\n",
    "#option0: pandas factorizing: maps each category to a different integer = label encoder \n",
    "\n",
    "#create series for pandas\n",
    "\n",
    "region = data[\"region\"] # series \n",
    "region_encoded, region_categories = pd.factorize(region)\n",
    "factor_region_mapping = dict(zip(region_categories, region_encoded)) #mapping of encoded numbers and original categories. \n",
    "\n",
    "print(\"Pandas factorize function for label encoding with series\")  \n",
    "print(region[:10]) #original version \n",
    "print(region_categories) #list of categories\n",
    "print(region_encoded[:10]) #encoded numbers for categories \n",
    "print(factor_region_mapping) # print factor mapping\n",
    "\n",
    "#option1: pandas get_dummies: maps each category to 0 (cold) or 1 (hot) = one hot encoder \n",
    "\n",
    "#create series for pandas\n",
    "region = data[\"region\"] # series \n",
    "region_encoded = pd.get_dummies(region, prefix='')\n",
    "\n",
    "print(\"Pandas get_dummies function for one hot encoding with series\")  \n",
    "\n",
    "print(region[:10]) #original version \n",
    "print(region_encoded[:10]) #encoded numbers for categories \n",
    "\n",
    "#option2: sklearn label encoding: maps each category to a different integer\n",
    "\n",
    "#create ndarray for label encodoing (sklearn)\n",
    "sex = data.iloc[:,1:2].values\n",
    "smoker = data.iloc[:,4:5].values\n",
    "\n",
    "#label encoder = le\n",
    "\n",
    "# le for sex\n",
    "le = LabelEncoder()\n",
    "sex[:,0] = le.fit_transform(sex[:,0])\n",
    "sex = pd.DataFrame(sex)\n",
    "sex.columns = ['sex']\n",
    "le_sex_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Sklearn label encoder results for sex:\")   \n",
    "print(le_sex_mapping)\n",
    "print(sex[:10])\n",
    "\n",
    "## le for smoker\n",
    "le = LabelEncoder()\n",
    "smoker[:,0] = le.fit_transform(smoker[:,0])\n",
    "smoker = pd.DataFrame(smoker)\n",
    "smoker.columns = ['smoker']\n",
    "le_smoker_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Sklearn label encoder results for smoker:\") \n",
    "print(le_smoker_mapping)\n",
    "print(smoker[:10])\n",
    "\n",
    "#option3: sklearn one hot encoding: maps each category to 0 (cold) or 1 (hot) \n",
    "\n",
    "#one hot encoder = ohe\n",
    "\n",
    "#create ndarray for one hot encodoing (sklearn)\n",
    "region = data.iloc[:,5:6].values #ndarray\n",
    "\n",
    "## ohe for region\n",
    "ohe = OneHotEncoder() \n",
    "\n",
    "region = ohe.fit_transform(region).toarray()\n",
    "region = pd.DataFrame(region)\n",
    "region.columns = ['northeast', 'northwest', 'southeast', 'southwest']\n",
    "print(\"Sklearn one hot encoder results for region:\")  \n",
    "print(region[:10])\n",
    "\n",
    "\n",
    "############################################01_05_DividingtheDataintoTestandTrain##############################################\n",
    "\n",
    "#putting the data together:\n",
    "\n",
    "##take the numerical data from the original data\n",
    "X_num = data[['age', 'bmi', 'children']].copy()\n",
    "\n",
    "##take the encoded data and add to numerical data\n",
    "X_final = pd.concat([X_num, region, sex, smoker], axis = 1)\n",
    "\n",
    "#define y as being the \"charges column\" from the original dataset\n",
    "y_final = data[['charges']].copy()\n",
    "\n",
    "#Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.33, random_state = 0 )\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data[['age']], y_final, test_size = 0.33, random_state = 0 )\n",
    "\n",
    "############################################01_06_FeatureScaling##############################################\n",
    "\n",
    "###normalized scaler (fit transform on train, fit only on test)\n",
    "#n_scaler = MinMaxScaler()\n",
    "#X_train = n_scaler.fit_transform(X_train.astype(np.float))\n",
    "#X_test= n_scaler.transform(X_test.astype(np.float))\n",
    "\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "s_scaler = StandardScaler()\n",
    "X_train = s_scaler.fit_transform(X_train.astype(np.float))\n",
    "X_test= s_scaler.transform(X_test.astype(np.float))\n",
    "\n",
    "\n",
    "############################################02_02_LinearRegression##############################################\n",
    "\n",
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print(\"lr.coef_: {}\".format(lr.coef_))\n",
    "print(\"lr.intercept_: {}\".format(lr.intercept_))\n",
    "print('lr train score %.3f, lr test score: %.3f' % (\n",
    "lr.score(X_train,y_train),\n",
    "lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr.coef_: [[ 3.62027494e+03  1.95077869e+03  6.85873820e+02  1.18478858e+17\n",
      "   1.20234031e+17  1.24970009e+17  1.22785507e+17 -3.64420788e+01\n",
      "   9.31222858e+03]]\n",
      "lr.intercept_: [13145.95343661]\n",
      "poly train score 0.789317, poly test score 0.817338\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree = 2)\n",
    "X_poly = poly.fit_transform(X_final)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_poly,y_final,test_size = 0.33, random_state = 0)\n",
    "\n",
    "s_scaler=StandardScaler()\n",
    "X_train = s_scaler.fit_transform(X_train)\n",
    "X_test = s_scaler.transform(X_test)\n",
    "\n",
    "poly_lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = poly_lr.predict(X_train)\n",
    "y_test_predict = poly_lr.predict(X_test)\n",
    "\n",
    "print(\"lr.coef_: {}\".format(lr.coef_))\n",
    "print(\"lr.intercept_: {}\".format(lr.intercept_))\n",
    "print('poly train score %3f, poly test score %3f'%(poly_lr.score(X_train,y_train),poly_lr.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 55)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 55 feature\n",
    "X_poly.shape\n",
    "# change degree can under or overfitting can do feature A* feature B and so on not explored in this course\n",
    "# More features may result in more overfitting, and in turn, worse results.\n",
    "# It may be a good idea to treat the degree for the polynomial features transform as a hyperparameter and test different values for your dataset."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
